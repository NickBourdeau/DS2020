{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science w/ Python Cheatsheet",
      "provenance": [],
      "collapsed_sections": [
        "VnwXR37Pwp73",
        "qTp8FH5bu51s"
      ],
      "authorship_tag": "ABX9TyPbi2+hylzp9pV5cpXt2p5G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickBourdeau/DS2020/blob/master/Data_Science_w_Python_Cheatsheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq6WSWtsRERB",
        "colab_type": "text"
      },
      "source": [
        "An empty Python cheatsheet for various algorithms within the field of data science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3rGSBtXYAXa",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnwXR37Pwp73",
        "colab_type": "text"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NQh9XTW0cke",
        "colab_type": "text"
      },
      "source": [
        "### Line Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAPxKlzpX4-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams.update(mpl.rcParamsDefault)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piidT6KtucrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change colors and add labels\n",
        "plt.plot(x, y, color = '', label='')\n",
        "plt.plot(x, z, color = '', label='')\n",
        "plt.title('')\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.legend() # labels are specified in each line plot above\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05mRpI3h3wE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams.update(mpl.rcParamsDefault)\n",
        "fig, ax = plt.subplots(figsize=(3, 2)) # how to get the axes. you can also specify the figure size in here\n",
        "\n",
        "# remove the top and right border\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "ax.plot([1,2,3], [1,2,3], 'b--') # can also use plt.plot, which accesses the axes\n",
        "ax.set(title=\"\", xlabel=\"\", ylabel=\"\") # handy method to set all labels in one command\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPZ7jDOQ30pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12,9))\n",
        "ax.grid(True, linestyle=\"--\")\n",
        "\n",
        "ax.scatter(x, y, s=, edgecolors='', c=) # representing FOUR variables on the same graph\n",
        "\"\"\"\n",
        "    's' is setting the size of the markers\n",
        "    'edgecolors' is changing the color of the marker outlines\n",
        "\"\"\"\n",
        "\n",
        "ax.set(title=\"\", xlabel=\"\", ylabel=\"\")\n",
        "ax.text(0.16, 109000, \"\") # add plain text\n",
        "ax.annotate(\"\", (0.89, 50000), (0.79, 60000), arrowprops={'arrowstyle': '->'}) # add text with an arrow\n",
        "\n",
        "plt.savefig('', dpi=1000) # save the graph with high resolution!\n",
        "plt.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f4MHO-J1HSu",
        "colab_type": "text"
      },
      "source": [
        "### Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNVCfa15uxll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# can specify axis to help with interpretability (think integrity)\n",
        "plt.scatter(x, y)\n",
        "plt.title('')\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.ylim(0, 8) # set y-axis limits (inclusive)\n",
        "# plt.xlim(start, end) # does the same thing but for x-axis\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fhT29Mg5W0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.title(\"\", weight = 'bold', size = 16)\n",
        "plt.xlabel(\" \", weight = 'bold', size = 14)\n",
        "plt.ylabel(\"\", weight = 'bold', size = 14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEJBtGjF5kRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize scatterplot, with red-to-blue color map\n",
        "plt.style.use('default')\n",
        "plt.scatter(x,y, c=, \n",
        "            cmap = , edgecolors = , linewidths = 0.7)\n",
        "plt.title(\"\", weight = \"bold\")\n",
        "plt.xlabel(\"\", weight = \"bold\")\n",
        "plt.ylabel(\"\", weight = \"bold\")\n",
        "cbar = plt.colorbar(shrink = 0.5)\n",
        "    #Add a colorbar of the red-blue spectrum to serve as a key \n",
        "plt.text(1.1, 65000, \"\", weight = \"bold\")\n",
        "plt.text(1.1, 31000, \"\", weight = \"bold\")\n",
        "    #Add labeling to the key for clarity   \n",
        "plt.text(0, 75000, \"r = \" + str(round(linregress(x, y).rvalue,2)), weight = \"bold\")\n",
        "    #Use linregress from scipy to obtain correlation coefficient for the vars\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mRcqOrB1O8L",
        "colab_type": "text"
      },
      "source": [
        "### Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7NxHTVI1SF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Histograms (for continuous variables)\n",
        "plt.hist(score, edgecolor='', color='') # edgecolor outlines the bars, color fills the bars\n",
        "plt.title('')\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4rcQhMW1X6w",
        "colab_type": "text"
      },
      "source": [
        "### Bargraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQG_UYzk1Zv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bar graphs (for categorical variables)\n",
        "plt.bar(x, count)\n",
        "plt.title('')\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA4XtFvM-w98",
        "colab_type": "text"
      },
      "source": [
        "### ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxLfefkA-yfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "probs = val_model.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('ROC Curve for First Model')\n",
        "plt.plot(fpr, tpr, 'r', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate');\n",
        "plt.savefig('roc_first_model.png', format='png', dpi=1200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTp8FH5bu51s",
        "colab_type": "text"
      },
      "source": [
        "## Seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoLajcaw1wao",
        "colab_type": "text"
      },
      "source": [
        "### Linegraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgRoAjVmu4ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu2oyb_D10R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Line plots\n",
        "sns.set_palette('', 10) # can optionally change palette\n",
        "\n",
        "sns.relplot(x= '', y = '', kind = 'line', data = ) # specify the kind='line'\n",
        "# automatically adds axis labels\n",
        "plt.title('') # combining seaborn and matplotlib.pyplot\n",
        "plt.show() # don't technically need this, but it helps format the printout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ZEJIEP2CCg",
        "colab_type": "text"
      },
      "source": [
        "### Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE7pv16D15n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scatterplot\n",
        "sns.relplot(x='', y = '', kind='', data = , color='') # default for kind='scatter'\n",
        "plt.title('') # adds a title\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xpyF1sVxael",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding more information to the graph\n",
        "sns.relplot(x='', y='', hue = '', data = ) # use the hue parameter to specify color categories\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkqfgIQuxbv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# changing point shapes\n",
        "sns.relplot(x='', y='', style = '', color='', data = ) # could also change point style\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0K3TNcGxdEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# color as a continuous variable, Total number of people in the major\n",
        "sns.relplot(x='', y='', size = '', sizes = (15, 200), color='', data = ) \n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7eXxdmU2Ygy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combining the two plots above \n",
        "sns.relplot(x='', y='', hue = '', \n",
        "             size = '', sizes = (15, 200), data = )\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB4gcmwzxf41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting regression lines on scatterplots\n",
        "sns.lmplot(x = '', y='', data = )\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zSwuJjm2hVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# categorical variables\n",
        "sns.catplot(x = '', y = '', data = )\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EndXmta32jWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Option 1 to fix overlapping axis labels\n",
        "sns.catplot(x = '', y = '', data = )\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTtH1JDy2o4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can color points by any column\n",
        "sns.catplot(x = '', y = '', hue = '', data = )\n",
        "plt.title('')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Bf6jkd20Ys",
        "colab_type": "text"
      },
      "source": [
        "### Boxplots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKw2lg_X21_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Boxplots\n",
        "sns.catplot(x = '', y = '', kind = '', data = )\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu6alc2G26Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Boxen Plot - alternative to Box plot\n",
        "sns.catplot(x = '', y = '', kind = '', \n",
        "             data = )\n",
        "plt.title('')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4vIbM4y2-GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Violin Plot - alternative to Box plot and Boxen Plot\n",
        "sns.catplot(x = '', y = '', kind = '',   \n",
        "            data = )\n",
        "plt.title('')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0eDuXn3CLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How to plot violin plot to show more information\n",
        "sns.catplot(x = '', y = '', kind = '', \n",
        "            hue = '', split = '', data = )\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZ1naGg45He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,9))\n",
        "\n",
        "scatter = sns.scatterplot(x=, y=, hue=, size=, sizes=(10, 1000))\n",
        "scatter.legend(loc=(1,0.25)) # specify the legend location manually, otherwise it overlaps with the graph\n",
        "\n",
        "plt.title(\"\", fontdict={'fontsize': 20})\n",
        "plt.xlabel(\"\", fontdict={'fontsize': 16})\n",
        "plt.ylabel(\"\", fontdict={'fontsize': 16})\n",
        "plt.text(0.16, 109000, \"\") # add plain text\n",
        "plt.text(0.75, 60000, \"\")\n",
        "plt.arrow(0.89, 50000, -0.1, 10000)\n",
        "plt.annotate(\"\", (0.89, 50000), (0.79, 60000), ) # add text with an arrow\n",
        "\n",
        "plt.savefig('', dpi=300, bbox_inches=\"tight\") # the legend box was getting cut off, so the solution was bbox_inches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l32wAdQ3J-t",
        "colab_type": "text"
      },
      "source": [
        "### Bargraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMvyKtNW3Lk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bar plots - known as count plots within seaborn's documentation\n",
        "sns.catplot(x='', kind='', data=)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('')\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crwxztw43PzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.catplot(x='', kind='', hue=' ', data=)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('N')\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO_YuPdk-Gdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(12,6))\n",
        "sns.barplot(x='', y='', hue='', data = pay_groups, ax = axes[0]);\n",
        "axes[0].title.set_text('')\n",
        "axes[0].set_xlabel('')\n",
        "axes[0].set_ylabel('')\n",
        "\n",
        "sns.barplot(x='', y='', hue='', data = pay2_groups, ax=axes[1]);\n",
        "axes[1].title.set_text('')\n",
        "axes[1].set_xlabel('')\n",
        "axes[1].set_ylabel('')\n",
        "  \n",
        "plt.suptitle('', fontsize=17);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNO2FRJU4weZ",
        "colab_type": "text"
      },
      "source": [
        "### Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMwbZe304ym6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style=\"white\")\n",
        "\n",
        "# Create a correlation matrix\n",
        "corr = housing.corr()\n",
        "\n",
        "# Create a mask for the upper triangle by creating an array of zeros with the same shape, size, type\n",
        "mask = np.zeros_like(corr, dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "fig, ax = plt.subplots(figsize=(11,9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr,mask=mask,cmap=cmap,vmax=1,center=0,square=True, linewidth=.5, cbar_kws={'shrink': .5})\n",
        "ax.set_title('')\n",
        "\n",
        "plt.savefig('Multicollinearity Heat Map.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wSkfxA39_m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=[20, 10])\n",
        "sns.heatmap(df.corr(), annot=True, fmt='.2g', mask=np.tril(df.corr()));\n",
        "plt.suptitle('', fontsize=25);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1r0-Qx6vtUf",
        "colab_type": "text"
      },
      "source": [
        "## Plotly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NX4Ml0uv255",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7DOGoJL6Slz",
        "colab_type": "text"
      },
      "source": [
        "### Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSOyMJWgv453",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = px.scatter(df, x = '', y = '', trendline=\"ols\")\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_njsjCHv6dBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = px.scatter(df, x = '', y = '', trendline=\"ols\")\n",
        "fig.update_layout(title = \"\", xaxis_title=\"\", \n",
        "                  yaxis_title = \"\", font = {\"size\":15, \"color\":\"#4f4f4f\"}\n",
        "                  )\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRawwtDq6tCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#customizing\n",
        "fig = px.scatter(df, x = '', y = '', size = \"\")\n",
        "fig.update_layout(title = \"\", xaxis_title=\"\", \n",
        "                  yaxis_title = \"\", font = dict(\n",
        "                      size=15,\n",
        "                      color = \"#4f4f4f\"\n",
        "                  ))\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93OkOYGu63ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = px.scatter(df, x = '', y = '', size = \"\", size_max=40,\n",
        "                 color = \"\")\n",
        "fig.update_layout(title = \"\", xaxis_title=\"\", \n",
        "                  yaxis_title = \"\", font = dict(\n",
        "                      size=15,\n",
        "                      color = \"#4f4f4f\"\n",
        "                  ))\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB_yn-a-wIAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff #for more specialized plots"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGoP5G25wNqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Subplots \n",
        "from plotly.subplots import make_subplots\n",
        "fig = make_subplots(rows = 1, cols = 3)\n",
        "\n",
        "#Now, add traces to the subplots through saying the row = and column = at the end. \n",
        "\n",
        "fig.add_trace(go.Scatter(x = , y = , mode=\"markers\"), row = 1, col = 1)\n",
        "fig.add_trace(go.Bar(x = , y = ), row = 1, col=2)\n",
        "fig.add_trace(go.Histogram(x = ), row = 1, col = 3)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KTOA_e7wUAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "styles = [\"plotly\", \"plotly_white\", \"plotly_dark\", \"seaborn\", \"ggplot2\", \"simple_white\", \n",
        "          \"none\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3QnB53Pwbzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = go.Figure()\n",
        "mcats = df.category.unique()\n",
        "for cat in mcats: \n",
        "  child = df[df.category == ]\n",
        "\n",
        "  fig.add_trace(go.Scatter( name = ,\n",
        "      x = , y = , hovertext=, hoverinfo=\"text\", \n",
        "      mode = \"markers\",  marker = dict(size = , sizemode=\"area\", sizeref=200, \n",
        "                                       )\n",
        "  ))\n",
        "\n",
        "\n",
        "fig.update_layout(title = \"\", xaxis_title=\"\", \n",
        "                  yaxis_title = \"\", font = dict(\n",
        "                      size=15\n",
        "                  ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTTPrKOc_Jdc",
        "colab_type": "text"
      },
      "source": [
        "### Bar Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6NSFvMq_LAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "fig1 = px.bar(importance1, x=importance1.index, y = 'Importance', labels={'x':'Feature'})\n",
        "fig1.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKqDId2q1cpH",
        "colab_type": "text"
      },
      "source": [
        "## GGplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_42T7tGb1gxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from plotnine import ggplot, geom_bar, geom_point, aes, geom_smooth, stat_smooth, facet_wrap, labs\n",
        "from plotnine.data import mpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpxghk6u1lpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(ggplot(mpg)\n",
        " + aes(x ='', y = '', color = '')\n",
        " + geom_point(color = '')\n",
        " + geom_smooth\n",
        " + facet_wrap()\n",
        " + labs(title = '', x = '', y ='')\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxXNgXdA1qc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(ggplot(mpg, aes(x='', y='', fill='trans'))\n",
        " + geom_col(stat='', position='')) +  labs(title=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1oBvJHx2NwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ggplot(mpg, aes(x='', fill=''))+geom_density(alpha=0.3)+labs(title=\"\", x = \"\", y = \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G7aiRYH2Q6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ggplot(mpg, aes(x='cty', fill='drv'))+geom_density(alpha=0.3)+labs(title=\"\", x = \"\", y = \"\")+facet_wrap('~class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbjHS8lQRBnr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im3jNBRl2bfC",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-fLSiv528dq",
        "colab_type": "text"
      },
      "source": [
        "# Geo-Spatial Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C53e4ES929on",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import geopandas as gpd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUPmTmSC3PZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "world = gpd.read_file(gpd.datasets.get_path(''))\n",
        "world\n",
        "\n",
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "world_deaths.plot(column='', ax=ax, legend=True, \n",
        "                  legend_kwds={'':'horizontal',\n",
        "                  'label': ''},\n",
        "                  cmap='OrRd',\n",
        "                  edgecolor = 'black',\n",
        "                  linewidth = 0.1)\n",
        "plt.title('')\n",
        "ax.spines[\"top\"].set_visible(False)  \n",
        "ax.spines[\"right\"].set_visible(False)\n",
        "ax.spines[\"left\"].set_visible(False)  \n",
        "ax.spines[\"bottom\"].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.yaxis.set_visible(False)\n",
        "#plt.savefig('world_deaths.png', dpi = 1200)\n",
        "#world_deaths.plot(column='total_deaths')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcQe0opX3Zr9",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ZFDKtY8S1n",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rWT1mRyuyZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sperate train and test data\n",
        "split_data = train_test_split(x,y, test_size = 0.1)\n",
        "\n",
        "train_x = np.array(split_data[0]).reshape((-1, 1))\n",
        "test_x = np.array(split_data[1]).reshape((-1, 1))\n",
        "train_y = np.array(split_data[2])\n",
        "test_y = np.array(split_data[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2URDMq_uzTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit the model\n",
        "model = LinearRegression().fit(train_x, train_y)\n",
        "\n",
        "lm = LinearRegression()\n",
        "lm.fit(train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNCEgGR_u1WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# observe/evaluate the model\n",
        "r_sq = model.score(train_x, train_y)\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "print('R-squared:', r_sq)\n",
        "print('intercept:', model.intercept_)\n",
        "print('slope:', model.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lTw1F6Ou2-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find predictions\n",
        "y_pred = model.predict(test_x)\n",
        "y_pred = model.intercept_ + model.coef_ * test_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDEDLUdV71ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example\n",
        "## I reshaped y to put all of the values on the same scale\n",
        "Xs = data.drop(['percent fat'], axis = 1)\n",
        "y = data['percent fat'].values.reshape(-1,1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.30, random_state=40)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train,y_train)\n",
        "\n",
        "pred_train_lr= lin_reg.predict(X_train)\n",
        "print(\"MSE on training: \",np.sqrt(mean_squared_error(y_train,pred_train_lr)))\n",
        "print(\"R2 on training: \",r2_score(y_train, pred_train_lr))\n",
        "\n",
        "pred_test_lr= lin_reg.predict(X_test)\n",
        "print(\"MSE on testing: \", np.sqrt(mean_squared_error(y_test,pred_test_lr))) \n",
        "print(\"R2 on testing: \", r2_score(y_test, pred_test_lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjrNwZg1vUSw",
        "colab_type": "text"
      },
      "source": [
        "## Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrOQsH3svWDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create a vector for your parameters, and set them to zero\n",
        "X = df[:,0]\n",
        "y = df[:,1]\n",
        "m = len(y)\n",
        "\n",
        "X = X[:,np.newaxis] # convert to array\n",
        "y = y[:,np.newaxis] # convert to array\n",
        "ones = np.ones((m,1)) # required to account for intercepts (complicated proof)\n",
        "X = np.hstack((ones, X)) # adding the intercept term\n",
        "\n",
        "theta = np.array([.5,0.7])\n",
        "\n",
        "def cost_function(theta,X,Y):\n",
        "  inner = np.power(((X * theta.T) - Y), 2)\n",
        "  return np.sum(inner) / (2 * len(X))\n",
        "  \n",
        "print(cost_function(theta, X, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G3x2ZnOvdoF",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_rUbYPrvfUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = None\n",
        "iterations = None\n",
        "alpha = 0.01\n",
        "\n",
        "def run_gradient_descent(theta,X,y,iterations,alpha):\n",
        "  theta = np.array([0,0])\n",
        "  for i in range(iterations):\n",
        "    temp = np.dot(X, theta) - y\n",
        "    temp = np.dot(X.T, temp)\n",
        "    theta = theta - ((alpha/m).dot(temp))\n",
        "  return theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeUhMHi0viUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = np.zeros([2,1])\n",
        "iterations = 1500\n",
        "alpha = 0.01\n",
        "m = len(X)\n",
        "\n",
        "print(run_gradient_descent(theta, X, y, iterations, alpha))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9_nBvG2v5Pq",
        "colab_type": "text"
      },
      "source": [
        "## Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TapdBsRIv75u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create X and y\n",
        "feature_cols = ['', '', '']\n",
        "X = data[feature_cols]\n",
        "y = data.sales\n",
        "\n",
        "# instantiate and fit\n",
        "lm2 = LinearRegression()\n",
        "lm2.fit(X, y)\n",
        "\n",
        "# print the coefficients\n",
        "print(lm2.intercept_)\n",
        "print(lm2.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7EsbbrjwL4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pair the feature names with the coefficients\n",
        "list(zip(feature_cols, lm2.coef_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFCeQQfTwMg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create X and y\n",
        "feature_cols = ['', '', '']\n",
        "X2 = np.array(data.iloc[:, :-1])\n",
        "y = np.array(data['sales']).reshape(-1, 1)\n",
        "\n",
        "# instantiate and fit\n",
        "reg2 = LinearRegression().fit(X2,y)\n",
        "pred2 = reg2.predict(X2)\n",
        "\n",
        "# print the coefficients\n",
        "print(reg2.intercept_)\n",
        "print(reg2.coef_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLQ-oJTewUBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pair the feature names with the coefficients\n",
        "list(zip(feature_cols, reg2.coef_[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8oWW7h2BM3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example\n",
        "X_data = iris[['', '']]\n",
        "Y_data = iris['']\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.2) \n",
        "lin = LinearRegression()\n",
        "lin.fit(x_train, y_train)\n",
        "print(lin.coef_)\n",
        "print(lin.intercept_)\n",
        "print(r2_score(lin.predict(x_train), y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fzw-RpUwZLv",
        "colab_type": "text"
      },
      "source": [
        "## Initial Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKSrqNgywba4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find r^2 and then adjust to the adjusted R^2 formula\n",
        "r2 = reg.score(X, y)\n",
        "r22 = reg2.score(X2, y)\n",
        "\n",
        "print(1 - (((1-r2)*(len(y)-1))/(len(y)-1-1)))\n",
        "print(1 - (((1-r22)*(len(y)-1))/(len(y)-3-1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whrPHgNfwdyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "X = np.array(data['']).reshape(-1, 1)\n",
        "y = np.array(data[''])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1yVS1QDwf-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm1_f = f_regression(X, y)\n",
        "\n",
        "print('\\t','TV', '\\n', 'F-stat', lm1_f[0], '\\n', 'p-value', lm1_f[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8zx_4gbwie6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm2_f = f_regression(X2, y)\n",
        "\n",
        "print(feature_cols, '\\n', 'F-stat', lm2_f[0], '\\n', 'p-value', lm2_f[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyd6ABz82k6M",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kX11cCpwsIK",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZXcoDVUw8oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Formating needed by Scikit-learn\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "print(\"<--- Data shape --->\")\n",
        "print(\"Shape of X, and example:\",x_train.shape)\n",
        "print(x_train[0])\n",
        "\n",
        "print(\"Shape of Y, and example:\",y_train.shape)\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG_HgHkXw9UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "## Get a sense of what the correct results look like\n",
        "logisticRegr = LogisticRegression(solver='liblinear',fit_intercept=True)\n",
        "\n",
        "# solver : str, {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, optional (default=’liblinear’).\n",
        "# Algorithm to use in the optimization problem.\n",
        "\n",
        "# For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
        "# For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
        "# ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
        "# ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
        "# ‘saga’ also supports ‘elasticnet’ penalty\n",
        "# ‘liblinear’ does not handle no penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk5KWQ4VxAyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = logisticRegr.fit(x_train, y_train)\n",
        "print(\"Test accuracy:\")\n",
        "print(logisticRegr.score(x_test,y_test))\n",
        "print(\"Vector with coefficient values for theta_1, theta_2\")\n",
        "print(\"theta_0\",logisticRegr.intercept_[0],\"theta_1, theta_2 = \",logisticRegr.coef_[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_M9StZPxkMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get training data\n",
        "training = df.iloc[0:20]\n",
        "\n",
        "# for the training set...\n",
        "\n",
        "# remove non predictive variables \n",
        "train = training.drop(['', '', ''], 1)\n",
        "\n",
        "# Isolate x (features) and y (output/response) for Charlie\n",
        "train_x = train.drop('', 1)\n",
        "train_y = train['']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi0N8mSTxwR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Isolate testing data\n",
        "testing = df.iloc[20:25]\n",
        "# Do the same for the test set\n",
        "test = testing.drop(['', '', ''], 1)\n",
        "\n",
        "test_x = test('', 1)\n",
        "test_y = test['']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6XWYr3Ux7YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LogisticRegression(fit_intercept=False)\n",
        "clf.fit(train_x, train_y)\n",
        "\n",
        "predicted = np.array(clf.predict(test_x))\n",
        "test_array = np.array(test_y)\n",
        "\n",
        "print('Predictions:', predicted)\n",
        "print('Actual:     ', test_array)\n",
        "\n",
        "matches = predicted == test_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSSkxSsyIlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = train_x.columns.values\n",
        "list(zip(features, clf.coef_[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrgytFOBX83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example\n",
        "log = LogisticRegression()\n",
        "log.fit(x_train, y_train)\n",
        "y_predict = log.predict(x_test)\n",
        "y_proba = log.predict_proba(x_test)\n",
        "print(accuracy_score(y_predict, y_test)) # instead of r2_score, categorical variables use the accuracy_score to check accuracy\n",
        "log.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdrOf3zkBjIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = pd.DataFrame(y_predict)\n",
        "pd.concat([y_test.reset_index(), y_predict], axis=1).set_index('index') # to show where the differences are"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-zOygUl2noo",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YthTzPUO4g3j",
        "colab_type": "text"
      },
      "source": [
        "# Regression Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZpq2DUD4jDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from patsy import dmatrices\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Gather features\n",
        "features = \"+\".join(housing.loc[:, housing.columns != 'price'])\n",
        "\n",
        "# Get y and X dataframes based on multiple regression\n",
        "# price ~ featrues: prices is regressed on features\n",
        "y, X = dmatrices('price ~' + features, housing, return_type='dataframe')\n",
        "\n",
        "# Calculate VIF\n",
        "# For each X, calculate VIF and save in dataframe\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Features\"] = X.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Round to one decimal point\n",
        "vif.round(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM2A6iAv5GCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing inf VIF to really large values for the graph\n",
        "vif.loc[vif.VIF > 5.0, ['VIF']] = 10\n",
        "fig2, ax1 = plt.subplots(figsize=(11,9))\n",
        "fig2.set_size_inches(20,8)\n",
        "sns.barplot(data=vif,x=\"VIF\",y=\"Features\",ax=ax1,orient=\"h\",color=\"blue\")\n",
        "ax1.set(xlabel='VIF Scores', ylabel='Features',title=\"VIF: Testing for Multicollinearity of Features\")\n",
        "\n",
        "plt.savefig('Multicollinearity VIF.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQL_IN2y5Hk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting linear regression and estimating coefficients for the features\n",
        "from sklearn import linear_model\n",
        "\n",
        "lm = linear_model.LinearRegression()\n",
        "model = lm.fit(X,y)\n",
        "lm.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEc5XMeU5Jwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating data frames of the features and their estimated coefficients that we want to look at\n",
        "features3 = ['sqft_living','sqft_basement', 'sqft_above']\n",
        "coeff = [lm.coef_[0][4], lm.coef_[0][12], lm.coef_[0][11]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubnikt-k5Xh_",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OCnrlf94GEM",
        "colab_type": "text"
      },
      "source": [
        "# Regression Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUp5k1NS4IFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_data = train_test_split(x,y, test_size = 0.1)\n",
        "\n",
        "train_x = np.array(split_data[0]).reshape((-1, 1))\n",
        "test_x = np.array(split_data[1]).reshape((-1, 1))\n",
        "train_y = np.array(split_data[2])\n",
        "test_y = np.array(split_data[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBofEv4w4K_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(test_x)\n",
        "y_pred = model.intercept_ + model.coef_ * test_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chqhqpj04N7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(test_y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0cE9tfj4Udx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n",
        "rms = sqrt(mean_squared_error(test_y, y_pred))\n",
        "rms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsot7jyZ4Wa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(test_y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMwpSVfr4X5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.formula.api as sm\n",
        "models = sm.ols(formula=(train_x, train_y), data=split_data)\n",
        "fitted1 = models.fit()\n",
        "fitted1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvpMZZYc4aZg",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt96ZP7c7_cr",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGFFFiF18ChD",
        "colab_type": "text"
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRnN6jzb8Arj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "\n",
        "ridge = Ridge()\n",
        "\n",
        "### Here, I'm plugging in different values for lambda and choosing the one that models things best\n",
        "parameters = {'alpha': [10 ** a for a in range(-6, 6)]}\n",
        "\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error',cv=5)\n",
        "ridge_regressor.fit(Xs,y)\n",
        "\n",
        "print(\"Best alpha value: \", ridge_regressor.best_params_['alpha'])\n",
        "\n",
        "## Now, I'm creating a ridge regression using the calculated alpha, and running it on our data\n",
        "model_ridge = Ridge(alpha=10)\n",
        "model_ridge.fit(X_train, y_train) \n",
        "\n",
        "pred_train_ridge= model_ridge.predict(X_train)\n",
        "print(\"MSE on training: \", np.sqrt(mean_squared_error(y_train,pred_train_ridge))) \n",
        "print(\"R2 on training: \", r2_score(y_train, pred_train_ridge))\n",
        "\n",
        "pred_test_ridge= model_ridge.predict(X_test)\n",
        "print(\"MSE on testing: \", np.sqrt(mean_squared_error(y_test,pred_test_ridge))) \n",
        "print(\"R2 on testing: \", r2_score(y_test, pred_test_ridge))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDnEv47v8Ln_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##These are the coefficients given to each feature using the ridge regression model.\n",
        "#Features with greater absolute coefficients are the \"mose stressed\" features\n",
        "# Each index in the array corresponds to the column in the dataset at that index\n",
        "print(\"Coefficients given to each predictor: \\n\", model_ridge.coef_[0], \"\\n\")\n",
        "\n",
        "sorted_coef = np.argsort(np.abs(model_ridge.coef_[0]))\n",
        "#np.argsort sorts from least to greatest, so I reverse the array\n",
        "sorted_coef = np.flip(sorted_coef)\n",
        "\n",
        "print(\"Predictors, ordered by absolute coefficient: \\n\")\n",
        "for item in sorted_coef:\n",
        "  print(Xs.columns[item] + \": \" ,model_ridge.coef_[0][item])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK4IVIsF8Pa8",
        "colab_type": "text"
      },
      "source": [
        "## Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opZ5kxKT8TLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "\n",
        "lasso = Lasso()\n",
        "### Here, I'm plugging in different values for lambda and choosing the one that models things best\n",
        "parameters = {'alpha': [10 ** a for a in range(-6, 6)]}\n",
        "\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error',cv=5)\n",
        "lasso_regressor.fit(Xs,y)\n",
        "\n",
        "print(\"Best alpha value: \", lasso_regressor.best_params_['alpha'])\n",
        "\n",
        "model_lasso = Lasso(alpha=2)\n",
        "model_lasso.fit(X_train, y_train) \n",
        "pred_train_lasso= model_lasso.predict(X_train)\n",
        "\n",
        "\n",
        "pred_train_lasso= model_lasso.predict(X_train)\n",
        "print(\"MSE on training: \", np.sqrt(mean_squared_error(y_train,pred_train_lasso))) \n",
        "print(\"R2 on training: \", r2_score(y_train, pred_train_lasso))\n",
        "\n",
        "pred_test_lasso= model_lasso.predict(X_test)\n",
        "print(\"MSE on testing: \", np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
        "print(\"R2 on testing: \", r2_score(y_test, pred_test_lasso))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWLfzo028Vp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##These are the coefficients given to each feature using the ridge regression model.\n",
        "#Features with greater absolute coefficients are the \"mose stressed\" features\n",
        "# Each index in the array corresponds to the column in the dataset at that index\n",
        "print(\"Coefficients given to each predictor: \\n\", model_lasso.coef_, \"\\n\")\n",
        "\n",
        "sorted_l = np.argsort(np.abs(model_lasso.coef_))\n",
        "#np.argsort sorts from least to greatest, so I reverse the array\n",
        "sorted_l = np.flip(sorted_l)\n",
        "\n",
        "print(\"Predictors, ordered by absolute coefficient: \\n\")\n",
        "for item in sorted_l:\n",
        "  print(Xs.columns[item] + \": \" ,model_lasso.coef_[item])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-9-P67m8Yna",
        "colab_type": "text"
      },
      "source": [
        "## Forward Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaSjhwyS8Z6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sm\n",
        "#creates a function for forward selection\n",
        "def forward_select(X, y, significance_level=0.05):\n",
        "    initial_features = X.columns.tolist()\n",
        "    best_features = []\n",
        "    while (len(initial_features)>0):\n",
        "        remaining_features = list(set(initial_features)-set(best_features))\n",
        "        new_pval = pd.Series(index=remaining_features)\n",
        "        for new_column in remaining_features:\n",
        "            model = sm.OLS(y, sm.add_constant(X[best_features+[new_column]])).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        min_p_value = new_pval.min()\n",
        "        if(min_p_value<significance_level):\n",
        "            best_features.append(new_pval.idxmin())\n",
        "        else:\n",
        "            break\n",
        "    return best_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0d8KZqM8fjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_select(X_train,y_train)\n",
        "features = forward_select(X_train, y_train)\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2SAf4w_8lFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train[features], y_train)\n",
        "y_pred = regr.predict(X_test[features])\n",
        "forward_mse=mean_squared_error(y_test, y_pred)\n",
        "forward_r2=r2_score(y_test, y_pred)\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQZtNLZr8mlq",
        "colab_type": "text"
      },
      "source": [
        "## Backwards Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srz1hyr48oUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defines function for backwards selection \n",
        "\n",
        "def backward_elimination(X, y,significance_level = 0.05):\n",
        "    features = X.columns.tolist()\n",
        "    while(len(features)>0):\n",
        "        features_with_constant = sm.add_constant(X[features])\n",
        "        p_values = sm.OLS(y, features_with_constant).fit().pvalues[1:]\n",
        "        max_p_value = p_values.max()\n",
        "        if(max_p_value >= significance_level):\n",
        "            excluded_feature = p_values.idxmax()\n",
        "            features.remove(excluded_feature)\n",
        "        else:\n",
        "            break \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_k4L0xK8qZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#applies function to training data \n",
        "\n",
        "backwardsfeatures= backward_elimination(X_train,y_train)\n",
        "backwardsfeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szuia1Mp8rsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train[backwardsfeatures], y_train)\n",
        "y_pred = regr.predict(X_test[backwardsfeatures])\n",
        "forward_mse=mean_squared_error(y_test, y_pred)\n",
        "forward_r2=r2_score(y_test, y_pred)\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZn_LIt8uQb",
        "colab_type": "text"
      },
      "source": [
        "## Stepwise Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPX_I1WW8yDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates function for stepwise selection \n",
        "\n",
        "def stepwise_selection(X, y,SL_in=0.05,SL_out = 0.05):\n",
        "    initial_features = X.columns.tolist()\n",
        "    best_features = []\n",
        "    while (len(initial_features)>0):\n",
        "        remaining_features = list(set(initial_features)-set(best_features))\n",
        "        new_pval = pd.Series(index=remaining_features)\n",
        "        for new_column in remaining_features:\n",
        "            model = sm.OLS(y, sm.add_constant(X[best_features+[new_column]])).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        min_p_value = new_pval.min()\n",
        "        if(min_p_value<SL_in):\n",
        "            best_features.append(new_pval.idxmin())\n",
        "            while(len(best_features)>0):\n",
        "                best_features_with_constant = sm.add_constant(X[best_features])\n",
        "                p_values = sm.OLS(y, best_features_with_constant).fit().pvalues[1:]\n",
        "                max_p_value = p_values.max()\n",
        "                if(max_p_value >= SL_out):\n",
        "                    excluded_feature = p_values.idxmax()\n",
        "                    best_features.remove(excluded_feature)\n",
        "                else:\n",
        "                    break \n",
        "        else:\n",
        "            break\n",
        "    return best_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cgFFunb83O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#applies stepwise to training data\n",
        "\n",
        "stepwisefeatures= stepwise_selection(X_train,y_train)\n",
        "stepwisefeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dMPYlnE84yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train[stepwisefeatures], y_train)\n",
        "y_pred = regr.predict(X_test[stepwisefeatures])\n",
        "forward_mse=mean_squared_error(y_test, y_pred)\n",
        "forward_r2=r2_score(y_test, y_pred)\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z56_n9DZ8-2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model with all Predictors\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "forward_mse=mean_squared_error(y_test, y_pred)\n",
        "forward_r2=r2_score(y_test, y_pred)\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmhQLKd9AyM",
        "colab_type": "text"
      },
      "source": [
        "## Variance Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRnll2hO9DxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create threshold objects\n",
        "threshold = VarianceThreshold(threshold=.5)\n",
        "threshold2 = VarianceThreshold(threshold=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDywTTv59VIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform the training sets\n",
        "X_low_variance = threshold.fit_transform(xtr)\n",
        "X_high_variance = threshold2.fit_transform(xtr)\n",
        "X_high_variance[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvTuYctY9Wwr",
        "colab_type": "text"
      },
      "source": [
        "## Gini Coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU8yqzPT9agZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using random forest with all of the features as a baseline\n",
        "sel = RandomForestClassifier(n_estimators = 100)\n",
        "sel.fit(X_train,y_train)\n",
        "y_pred=sel.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nj78YDA9dJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Lr3TA29ex5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using select from model to analyze the most important features from Random Forest\n",
        "#Measured by Mean Impurity Decrease (MDI) -> This is the Gini impurity\n",
        "clf = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z6zCxLN9gHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding which features have above average importance in terms of decrease the Gini impurity\n",
        "#across all trees\n",
        "clf.get_support()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQdgB8Px9h3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding the number of names of the important features\n",
        "selected_feat= X_train.columns[(clf.get_support())]\n",
        "len(selected_feat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_e_Y0CT9uhX",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luShhojhClqG",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkKQnyAYCm3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping rows with missing values\n",
        "dropped = df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDl76gC5CqDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.fillna(0) # replace missing values with 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xqg_Cf9Crk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[0].fillna(df[0].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6GJTG9JCtLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.fillna(method='ffill') # forward-fill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoUbfwPtCuZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.fillna(method='bfill') # back-fill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P_XJzK-CvzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTvMxuYkC9ro",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJcQR4T493ve",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDK-VXoO-Zpz",
        "colab_type": "text"
      },
      "source": [
        "## K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcW1hnmW95cF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy of First Logistic Regression Model using K-Fold Cross Validation')\n",
        "\n",
        "k_fold_5_model = LogisticRegression(solver='saga')\n",
        "k_fold_5_scores = cross_val_score(k_fold_5_model, x_regressors, y_regressors, cv=5)\n",
        "print('   5-Fold:', round(k_fold_5_scores.mean()*100, 2), '%')\n",
        "\n",
        "k_fold_10_model = LogisticRegression(solver='saga')\n",
        "k_fold_10_scores = cross_val_score(k_fold_10_model, x_regressors, y_regressors, cv=10)\n",
        "print('   10-Fold:', round(k_fold_10_scores.mean()*100, 2), '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEYfvabT-75f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dmodel = dtree\n",
        "accuracy2 = cross_val_score(dmodel, A, b, scoring='accuracy', cv = 10)\n",
        "print('Accuracy of Decision Tree Model with Cross Validation is:', accuracy2.mean() * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7PD3r7n-9rV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rforest = RandomForestClassifier(random_state=2)\n",
        "model3 = rforest\n",
        "accuracy3 = cross_val_score(model3, A, b, scoring='accuracy', cv = 10)\n",
        "print('Accuracy of Random Forest Model with Cross Validation is:', accuracy3.mean() * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb8Dq9xf-i18",
        "colab_type": "text"
      },
      "source": [
        "## LOOCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9b26hd2-kE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loocv_model = LogisticRegression(solver='saga')\n",
        "loocv_scores = cross_val_score(loocv_model, x_2_regressors, y_2_regressors, cv = LeaveOneOut())\n",
        "loocv_scores.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXxTnITo-mQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loocv_scores = cross_val_score(loocv_model, x_3_regressors, y_3_regressors, cv = LeaveOneOut())\n",
        "print('Accuracy of Logistic Regression Model with Regressors using LOOCV:')\n",
        "print('   ', round(loocv_scores.mean()*100, 4), '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJuYrZpQ_VLG",
        "colab_type": "text"
      },
      "source": [
        "## Recursive Feature Elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWUAJ5aV_aUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "rfe = RFECV(best, 3)\n",
        "fit = rfe.fit(A, b)\n",
        "\n",
        "rfe_predictions = rfe.predict(A_test)\n",
        "rfe.score(A_test, b_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXwlp8p5_dr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "cv = StratifiedKFold(10)\n",
        "visualizer = RFECV(best, cv=cv, scoring='f1_weighted')\n",
        "\n",
        "visualizer.fit(A, b)  \n",
        "visualizer.score(A_test, b_test)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j2x4zY0_fOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vis_accuracy = cross_val_score(visualizer, A, b, scoring='accuracy', cv = 10)\n",
        "print('Accuracy of Recursive Feature Elimination with Cross Validation is:', vis_accuracy.mean() * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q5BUw3C_isH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score\")\n",
        "plt.plot(range(1, len(visualizer.grid_scores_) + 1), visualizer.grid_scores_)\n",
        "plt.axvline(x=16)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4kfpkBj_k0h",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdBfMgjI_1ro",
        "colab_type": "text"
      },
      "source": [
        "# Grid Searches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXj0VifI_2zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd_train, cd_test, B_train, B_test = train_test_split(cd, B, test_size=0.2, random_state=2)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "max_depth = list(np.arange(1,10))\n",
        "max_depth.append(None)\n",
        "param_grid = { \n",
        "    'max_depth': max_depth,\n",
        "    'n_estimators': np.arange(100, 1100, 200), \n",
        "    'min_samples_split': [2,4,8,16],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "grid = GridSearchCV(estimator = rf, param_grid=param_grid, \n",
        "                          cv = 3, verbose = 51, n_jobs=-1)\n",
        "\n",
        "import time\n",
        "t_start = time.time()\n",
        "grid.fit(cd_train, Y_train)\n",
        "t_end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuLU1RCZ_5Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best = grid.best_estimator_\n",
        "best.fit(cd_train, B_train)\n",
        "accuracy_score(B_test, best.predict(cd_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNfnKVa1AAbY",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsLDSgmxZhZ",
        "colab_type": "text"
      },
      "source": [
        "# Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7eELbJGyRnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "dtree = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0LS26QIyYp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict for Charlie\n",
        "dtree.fit(train_x, train_y)\n",
        "\n",
        "predicted = np.array(dtree.predict(test_x))\n",
        "test_array = np.array(test_y)\n",
        "\n",
        "print('Predictions:', predicted)\n",
        "print('Actual:     ', test_array)\n",
        "\n",
        "matches = predicted == test_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6l7mudRyiRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(columns='')\n",
        "Y = df['']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXou3KnvzGpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "# model\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# train\n",
        "tree.fit(X_train, Y_train)\n",
        "\n",
        "# score\n",
        "\n",
        "print(tree.score(X_train, Y_train))\n",
        "print(tree.score(X_test, Y_test))\n",
        "\n",
        "# predict\n",
        "Y_predict = tree.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rkfu3GiCF3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example\n",
        "# model\n",
        "tree = DecisionTreeClassifier(random_state=2)\n",
        "forest = RandomForestClassifier(random_state=2)\n",
        "# many other criterion that you can look into\n",
        "\n",
        "# train\n",
        "tree.fit(x_train, y_train)\n",
        "forest.fit(x_train, y_train)\n",
        "\n",
        "# predict\n",
        "tree_predictions = tree.predict(x_test)\n",
        "forest_predictions = forest.predict(x_test)\n",
        "\n",
        "# feature importances\n",
        "tree_importance = pd.DataFrame({'Importance': tree.feature_importances_}, index = x_train.columns).sort_values('Importance', ascending = False)\n",
        "forest_importance = pd.DataFrame({'Importance': forest.feature_importances_}, index = x_train.columns).sort_values('Importance', ascending = False)\n",
        "\n",
        "# confusion matrix\n",
        "pd.crosstab(y_test, tree_predictions, rownames=['Actual'], colnames = ['Predicted:'], margins = True)\n",
        "pd.crosstab(y_test, forest_predictions, rownames=['Actual'], colnames = ['Predicted:'], margins = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpI2FkevB41w",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFsg6EQQB7ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(y_test, tree.predict(x_test), rownames=['Actual'], colnames = ['Predicted:'], margins=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVddzbZVzcnH",
        "colab_type": "text"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cFY_DN0zJbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree.feature_importances_\n",
        "list(zip(X_train.columns, tree.feature_importances_))\n",
        "pd.DataFrame({'Gain': tree.feature_importances_}, index = X_train.columns).sort_values('Gain', ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TON1xNfcze9s",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTzAMtjzzjBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(Y_test, Y_predict, rownames=['Actual'], colnames = ['Predicted:'], margins=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDU0GxJY2rPL",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBS0s6V4zmkx",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVoPnSPzocM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "forest = RandomForestClassifier(criterion = 'entropy')\n",
        "\n",
        "# train\n",
        "forest.fit(X_train, Y_train)\n",
        "\n",
        "# predict\n",
        "forest_predictions = forest.predict(X_test)\n",
        "\n",
        "# feature importances\n",
        "print(pd.DataFrame({'Importance': forest.feature_importances_}, index = X_train.columns).sort_values('Importance', ascending = False))\n",
        "\n",
        "# confusion matrix\n",
        "pd.crosstab(Y_test, forest_predictions, rownames=['Actual'], colnames = ['Predicted:'], margins = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycbBkNl5zrXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forest.score(X_test, Y_test) # mispredicted three samples (see above chart) \n",
        "# The random forest was worse than the single decision tree!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv44YKjrztDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X.shape[1]):\n",
        "    print(indices[f], importances[indices[f]])\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), indices)\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9lKxTLCzzW6",
        "colab_type": "text"
      },
      "source": [
        "### Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lA7faK1z8EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = pd.get_dummies(df[['Sex', 'Cabin', 'Title', 'PassengerClass']])\n",
        "y = df['Survived']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBRxZCk82ttM",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyEgTiQLz8rv",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnlK98BN0JQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "classifier = SVC(kernel=\"linear\")\n",
        "classifier.fit(X,np.ravel(y))\n",
        "\n",
        "# Test C = 100\n",
        "classifier2 = SVC(C=10,kernel=\"linear\")\n",
        "classifier2.fit(X,np.ravel(y))\n",
        "# Test C = 100\n",
        "classifier3 = SVC(C=20,kernel=\"linear\")\n",
        "classifier3.fit(X,np.ravel(y))\n",
        "# Test C = 100\n",
        "classifier4 = SVC(C=100,kernel=\"linear\")\n",
        "classifier4.fit(X,np.ravel(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyKJCdI30oqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_mat = loadmat(\"spamTrain.mat\")\n",
        "X_train =spam_mat[\"\"]\n",
        "y_train = spam_mat[\"\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrgP_iLO0pHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C =0.1\n",
        "spam_svc = SVC(C=0.1,kernel =\"linear\")\n",
        "spam_svc.fit(X_train,y_train.ravel())\n",
        "print(\"Training Accuracy:\",(spam_svc.score(X_train,y_train.ravel()))*100,\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uio0tv9Z0r97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_mat_test = loadmat(\"spamTest.mat\")\n",
        "X_test = spam_mat_test[\"Xtest\"]\n",
        "y_test =spam_mat_test[\"ytest\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4jr1vLT0ui9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_svc.predict(X_test)\n",
        "print(\"Test Accuracy:\",(spam_svc.score(X_test,y_test.ravel()))*100,\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpdc3YxpDAIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM Classifier model\n",
        "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\")) # Large C \n",
        "svm_clf.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFVhA85qDAry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training a polynomial classifier of degree 3\n",
        "poly3_svm_clf = SVC(kernel=\"poly\", gamma='auto', degree=3, coef0=1) # coef0 and gamma are other hyperparameters of a polynomial SVM.\n",
        "poly3_svm_clf.fit(X ,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TnT5lbkDz2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training an rbf classifier\n",
        "rbf_svm_clf = SVC(kernel=\"rbf\", gamma=5, C=0.001) # coef0 is another hyperparameter of the SVM.\n",
        "rbf_svm_clf.fit(X ,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tySrCKWpD2AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_IOfimq0ZMm",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8R05B570KuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset3Params(X, y, Xval, yval,vals):\n",
        "    \"\"\"\n",
        "    Returns your choice of C and sigma. You should complete this function to return the optimal C and \n",
        "    sigma based on a cross-validation set.\n",
        "    \"\"\"\n",
        "    acc = 0\n",
        "    best_c=0\n",
        "    best_gamma=0\n",
        "    for i in vals:\n",
        "        C= i\n",
        "        for j in vals:\n",
        "            gamma = 1/j\n",
        "            classifier = SVC(C=C,gamma=gamma)\n",
        "            classifier.fit(X,y)\n",
        "            prediction = classifier.predict(Xval)\n",
        "            score = classifier.score(Xval,yval)\n",
        "            if score>acc:\n",
        "                acc =score\n",
        "                best_c =C\n",
        "                best_gamma=gamma\n",
        "    return best_c, best_gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgSOkPnr0eK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vals = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
        "C, gamma = dataset3Params(X3, y3.ravel(), Xval, yval.ravel(),vals)\n",
        "classifier4 = SVC(C=C,gamma=gamma)\n",
        "classifier4.fit(X3,y3.ravel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWKmNDG-2vu-",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31nIbRVb5feT",
        "colab_type": "text"
      },
      "source": [
        "# Classification Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ftLF9kR5hdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code Walkthrough for creating an ROC Model -- using random numbers\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# generate 2 class dataset -- used with make_classification from sklearn\n",
        "#using a randomly generated dataset just for the purposes of \n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "\n",
        "\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
        "\n",
        "\n",
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(testy))]\n",
        "\n",
        "\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "\n",
        "# predict probabilities\n",
        "lr_probs = model.predict_proba(testX)\n",
        "\n",
        "\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "\n",
        "\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(testy, ns_probs)\n",
        "lr_auc = roc_auc_score(testy, lr_probs)\n",
        "\n",
        "\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=', (ns_auc))\n",
        "print('Logistic: ROC AUC=' ,(lr_auc))\n",
        "\n",
        "\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
        "\n",
        "\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "\n",
        "\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "\n",
        "\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiSQZ3La5shk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we know how to create an ROC model\n",
        "# We can use our previous dataset to actually create one\n",
        "\n",
        "#Create test splits and logistic regression\n",
        "X = data.drop([\"\"], 1)\n",
        "y = data[\"\"]\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, \n",
        "                                                    random_state=0)\n",
        "\n",
        "lgr = LogisticRegression(solver=\"lbfgs\")\n",
        "lgr.fit(train_x, train_y)\n",
        "\n",
        "# Save predicted values and predicted value probabilities (prob of being classed \"+\")\n",
        "pred = lgr.predict(test_x)\n",
        "pred_prob = lgr.predict_proba(test_x)[:, 1]\n",
        "\n",
        "\n",
        "print(\"Test accuracy:\")\n",
        "print(lgr.score(test_x,test_y))\n",
        "print(\"Vector with coefficient values for theta_1, theta_2\")\n",
        "print(\"theta_0:\",lgr.intercept_[0],\"theta_1, theta_2: = \",lgr.coef_[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-u9Fdh5ydv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC Graph\n",
        "fpr, tpr, thresholds = roc_curve(test_y, pred_prob)\n",
        "auc = roc_auc_score(test_y, pred_prob)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color=\"red\")\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"\")\n",
        "plt.title(\"\".format(round(auc, 4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVT5q3Kj57iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another way to evaluate a classification model is using a confusion matrix. \n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(test_y, pred)\n",
        "\n",
        "class_names=[0,1] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# create heatmap\n",
        "labels = [\"\",\"\",\"\",\"\"]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(pd.DataFrame(cm), annot=labels, cmap=\"Greens\" ,fmt='')\n",
        "\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('')\n",
        "plt.xlabel('')\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(test_y, pred))\n",
        "print(\"Precision:\",metrics.precision_score(test_y, pred))\n",
        "print(\"Recall:\",metrics.recall_score(test_y, pred))\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH2EK2I66GIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group_names = [\"\",\"\",\"\",\"\"]\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cm.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     cm.flatten()/np.sum(cm)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cm, annot=labels, fmt='', cmap='Greens')\n",
        "\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('')\n",
        "plt.xlabel('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4n5XcJy6Ryh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create random correlated data\n",
        "X_rand, y_rand = make_classification(n_samples=50000, n_classes=2, random_state=0)\n",
        "\n",
        "rand_train_x, rand_test_x, rand_train_y, rand_test_y = train_test_split(X_rand, y_rand, test_size=0.2, \n",
        "                                                    random_state=0)\n",
        "\n",
        "lgr_rand = LogisticRegression(solver=\"lbfgs\")\n",
        "lgr_rand.fit(rand_train_x, rand_train_y)\n",
        "\n",
        "# Save predicted values and predicted value probabilities (prob of being classed \"+\")\n",
        "pred_rand = lgr_rand.predict(rand_test_x)\n",
        "pred_prob_rand = lgr_rand.predict_proba(rand_test_x)[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbXFYDXC6YPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_graph(actual, probs):\n",
        "  num_points = 100\n",
        "  threshold = []\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1 = []\n",
        "  accuracy = []\n",
        "\n",
        "  t_inc = 1 / num_points\n",
        "\n",
        "  try:\n",
        "    actual = actual.reset_index(drop=True)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  for i in range(num_points):\n",
        "    t = i * t_inc\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for j in range(len(probs)):\n",
        "      # Classed as positive\n",
        "      if probs[j] > t:\n",
        "        # classed + and is actually +\n",
        "        if actual[j] == 1:\n",
        "          tp += 1\n",
        "        # classed + but is actually -\n",
        "        else:\n",
        "          fp += 1\n",
        "      # Classes as negative\n",
        "      else:\n",
        "        # classed - and is actually -\n",
        "        if actual[j] == 0:\n",
        "          tn += 1\n",
        "        else:\n",
        "          fn += 1\n",
        "\n",
        "    try:\n",
        "      p = tp / (tp + fp)\n",
        "    except ZeroDivisionError:\n",
        "      p = 1\n",
        "    try:\n",
        "      r = tp / (tp + fn)\n",
        "    except ZeroDivisionError:\n",
        "      r = 1\n",
        "    try:\n",
        "      a = (tp + tn) / (tp + tn + fp + fn)\n",
        "    except ZeroDivisionError:\n",
        "      a = 1\n",
        "\n",
        "    threshold.append(t)\n",
        "    precision.append(p)\n",
        "    recall.append(r)\n",
        "    f1.append(2 * (p * r) / (p + r))\n",
        "    accuracy.append(a)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(threshold, precision, label=\"Precision\")\n",
        "  ax.plot(threshold, recall, label=\"Recall\")\n",
        "  ax.plot(threshold, accuracy, label=\"Accuracy\")\n",
        "  ax.plot(threshold, f1, label=\"F1\")\n",
        "  plt.legend()\n",
        "  plt.title(\"Measures of Model Reliability v. Threshold\")\n",
        "  plt.xlabel(\"Threshold\")\n",
        "  plt.ylabel(\"Measure Value\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVzNOKIy6flg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_graph(test_y, pred_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_oH7evX6g4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_graph(rand_test_y, pred_prob_rand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9c9hbu96hVV",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fVQ9DNbEKp-",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZMSrFPsMU_z",
        "colab_type": "text"
      },
      "source": [
        "## Keras MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N4W1DirEMpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports for the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TWzJf9lMBjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants we'll use from now on\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ooMO5AVMwhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUxR9iT6ME93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(linewidth=150)\n",
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KgGOPa_MKsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting to floats\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Scaling the data between 0 and 1\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9XgslI2MOCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualizing the pixels as images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(y_train[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHo6FkJ9Mmy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Putting the data into the proper shape for Keras to work with it\n",
        "X_train_conv = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test_conv = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8q4Pg8GM2-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices (essentially One Hot Encoding)\n",
        "y_train_conv = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_conv = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH0ucFdgM3eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we have to use the \"flattened\" images like we did with the decision tree, logistic regression, etc.\n",
        "X_train_flat.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TQsIrNlM9Zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, input_shape=(784,), activation='sigmoid'))\n",
        "model.add(Dense(16, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6tsc5gmNCV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "history = model.fit(X_train_flat, y_train_conv, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test_flat, y_test_conv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyeAWsILNGmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#other model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
        "model.add(Flatten()) # turn 2D layer into 1D layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whIOUB5aNJHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "history = model.fit(X_train_conv, y_train_conv, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test_conv, y_test_conv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5dDqC5gNOra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Best model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsDXYhc6NQK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "history = model.fit(X_train_conv, y_train_conv, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test_conv, y_test_conv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB6fI_NONT4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6ro8RM_NXgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djQgJ7uuNXyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Accuracy: ' + str(acc))\n",
        "print('Training Loss: ' + str(loss))\n",
        "print('Test Accuracy: ' + str(val_acc))\n",
        "print('Test Loss: ' + str(val_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmf2oFjQNfGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test_conv, y_test_conv, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLACXrPUNfgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = model.predict(np.array([X_test_conv[32]]))\n",
        "print(p)\n",
        "print(np.max(p))\n",
        "print(np.argmax(p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxIaf9OPNh-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X_test[32], cmap='gray', interpolation='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UpxhmSfOZAr",
        "colab_type": "text"
      },
      "source": [
        "# -------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXo8Xqj5Ob8G",
        "colab_type": "text"
      },
      "source": [
        "# NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQLV5bd3OeZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiled on: https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vefmsMruOxAY",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1U4tLonOmH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "\n",
        "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
        "tfv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_tfv =  tfv.transform(xtrain) \n",
        "xvalid_tfv = tfv.transform(xvalid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1gvIZJeO5Gt",
        "colab_type": "text"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sizHQ1oO7b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), stop_words = 'english')\n",
        "\n",
        "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
        "ctv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_ctv =  ctv.transform(xtrain) \n",
        "xvalid_ctv = ctv.transform(xvalid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJU9pgBeO-5-",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaX9VEIyPAOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting a simple Naive Bayes on TFIDF\n",
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AyHtzpKPJ1N",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU2LMo-dPLQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(xtrain)\n",
        "xtrain_svd = svd.transform(xtrain)\n",
        "xvalid_svd = svd.transform(xvalid)\n",
        "\n",
        "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
        "xvalid_svd_scl = scl.transform(xvalid_svd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU6RUa1vPZzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting a simple SVM\n",
        "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
        "clf.fit(xtrain_svd_scl, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd_scl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpUTWuzaPbuF",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS-_PgQdPc2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv.tocsc())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08RoorUrPohm",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDMV1MLhPpee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuR0OY9zPwPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize SVD\n",
        "svd = TruncatedSVD()\n",
        "    \n",
        "# Initialize the standard scaler \n",
        "scl = preprocessing.StandardScaler()\n",
        "\n",
        "# We will use logistic regression here..\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('svd', svd),\n",
        "                         ('scl', scl),\n",
        "                         ('lr', lr_model)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buLg3-rOPxwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {'svd__n_components' : [120, 180],\n",
        "              'lr__C': [0.1, 1.0, 10], \n",
        "              'lr__penalty': ['l1', 'l2']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxTpNah_Pzob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain\n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZnNYnrOQOT0",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKwXZIgpQZeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}